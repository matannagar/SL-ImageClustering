{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01ce0613",
   "metadata": {},
   "source": [
    "# The data\n",
    "This implementation will use the various images of ALS which we collected. The dataset contains more than 500 images of 25 different representational letters. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174b0736",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "we want python to point to the location where the images are located. This way instead of loading a whole file path, we can simply just use the name of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "032709ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_img allows us to load an image from a file as a PIL object\n",
    "from keras.preprocessing.image import load_img \n",
    "# img_to_array allows us to convert the PIL object into a NumPy array\n",
    "from keras.preprocessing.image import img_to_array \n",
    "# preproccess_input is meant to prepare your image into the format the model requires. \n",
    "# You should load images with the Keras load_img function so that you guarantee the images you load are compatible with the preprocess_input function.\n",
    "from keras.applications.vgg16 import preprocess_input \n",
    "\n",
    "# for everything else\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "path = r\"C:\\Users\\matan\\My PC (DESKTOP-RLTMVS3)\\Desktop\\פרויקט גמר\\dataset\\dark photos\"\n",
    "# change the working directory to the path where the images are located\n",
    "os.chdir(path)\n",
    "\n",
    "# this list holds all the image filename\n",
    "flowers = []\n",
    "\n",
    "# creates a ScandirIterator aliased as files\n",
    "with os.scandir(path) as files:\n",
    "  # loops through each file in the directory\n",
    "    for file in files:\n",
    "        if file.name.endswith('.jpg'):\n",
    "          # adds only the image files to the flowers list\n",
    "            flowers.append(file.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82036b4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.jpg',\n",
       " '1217.jpg',\n",
       " '1220.jpg',\n",
       " '1221.jpg',\n",
       " '1237.jpg',\n",
       " '1238.jpg',\n",
       " '1239.jpg',\n",
       " '1247.jpg',\n",
       " '1248.jpg',\n",
       " '1250.jpg',\n",
       " '1251.jpg',\n",
       " '1257.jpg',\n",
       " '1261.jpg',\n",
       " '1277.jpg',\n",
       " '1279.jpg',\n",
       " '1290.jpg',\n",
       " '1297.jpg',\n",
       " '1318.jpg',\n",
       " '1330.jpg',\n",
       " '1337.jpg',\n",
       " '1338.jpg',\n",
       " '1341.jpg',\n",
       " '1349.jpg',\n",
       " '1350.jpg',\n",
       " '1377.jpg',\n",
       " '1378.jpg',\n",
       " '1379.jpg',\n",
       " '1397.jpg',\n",
       " '1399.jpg',\n",
       " '1400.jpg',\n",
       " '1409.jpg',\n",
       " '1418.jpg',\n",
       " '1440.jpg',\n",
       " '1441.jpg',\n",
       " '1448.jpg',\n",
       " '1449.jpg',\n",
       " '214.jpg',\n",
       " '222.jpg',\n",
       " '24.jpg',\n",
       " '259.jpg',\n",
       " '268.jpg',\n",
       " '287.jpg',\n",
       " '289.jpg',\n",
       " '297.jpg',\n",
       " '300.jpg',\n",
       " '301.jpg',\n",
       " '308.jpg',\n",
       " '309.jpg',\n",
       " '310.jpg',\n",
       " '317.jpg',\n",
       " '320.jpg',\n",
       " '327.jpg',\n",
       " '350.jpg',\n",
       " '366.jpg',\n",
       " '370.jpg',\n",
       " '377.jpg',\n",
       " '379.jpg',\n",
       " '380.jpg',\n",
       " '391.jpg',\n",
       " '394.jpg',\n",
       " '403.jpg',\n",
       " '404.jpg',\n",
       " '419.jpg',\n",
       " '422.jpg',\n",
       " '433.jpg',\n",
       " '437.jpg',\n",
       " '44.jpg',\n",
       " '441.jpg',\n",
       " '460.jpg',\n",
       " '462.jpg',\n",
       " '467.jpg',\n",
       " '473.jpg',\n",
       " 'A1.jpg',\n",
       " 'A13.jpg',\n",
       " 'A133.jpg',\n",
       " 'A134.jpg',\n",
       " 'A135.jpg',\n",
       " 'A14.jpg',\n",
       " 'A15.jpg',\n",
       " 'A2.jpg',\n",
       " 'A25.jpg',\n",
       " 'A26.jpg',\n",
       " 'A27.jpg',\n",
       " 'A3.jpg',\n",
       " 'A61.jpg',\n",
       " 'A62.jpg',\n",
       " 'A63.jpg',\n",
       " 'C1.jpg',\n",
       " 'C13.jpg',\n",
       " 'C14.jpg',\n",
       " 'C15.jpg',\n",
       " 'C2.jpg',\n",
       " 'C25.jpg',\n",
       " 'C26.jpg',\n",
       " 'C27.jpg',\n",
       " 'C3.jpg',\n",
       " 'C37.jpg',\n",
       " 'C38.jpg',\n",
       " 'C39.jpg',\n",
       " 'C49.jpg',\n",
       " 'C50.jpg',\n",
       " 'C51.jpg',\n",
       " 'D25.jpg',\n",
       " 'D26.jpg',\n",
       " 'D27.jpg',\n",
       " 'D37.jpg',\n",
       " 'D38.jpg',\n",
       " 'D39.jpg',\n",
       " 'del1002.jpg',\n",
       " 'del1028.jpg',\n",
       " 'del1031.jpg',\n",
       " 'del1040.jpg',\n",
       " 'del1129.jpg',\n",
       " 'del1133.jpg',\n",
       " 'del1138.jpg',\n",
       " 'del1160.jpg',\n",
       " 'del1169.jpg',\n",
       " 'del1180.jpg',\n",
       " 'del1310.jpg',\n",
       " 'del1313.jpg',\n",
       " 'del1528.jpg',\n",
       " 'del1603.jpg',\n",
       " 'del1782.jpg',\n",
       " 'E349.jpg',\n",
       " 'E350.jpg',\n",
       " 'E351.jpg',\n",
       " 'E361.jpg',\n",
       " 'E362.jpg',\n",
       " 'E363.jpg',\n",
       " 'E373.jpg',\n",
       " 'E374.jpg',\n",
       " 'E375.jpg',\n",
       " 'E385.jpg',\n",
       " 'E386.jpg',\n",
       " 'E387.jpg',\n",
       " 'G1.jpg',\n",
       " 'G13.jpg',\n",
       " 'G14.jpg',\n",
       " 'G15.jpg',\n",
       " 'G2.jpg',\n",
       " 'G25.jpg',\n",
       " 'G26.jpg',\n",
       " 'G27.jpg',\n",
       " 'G3.jpg',\n",
       " 'G37.jpg',\n",
       " 'G38.jpg',\n",
       " 'G39.jpg',\n",
       " 'G49.jpg',\n",
       " 'G50.jpg',\n",
       " 'G51.jpg',\n",
       " 'H37.jpg',\n",
       " 'H38.jpg',\n",
       " 'H39.jpg',\n",
       " 'H49.jpg',\n",
       " 'H50.jpg',\n",
       " 'H51.jpg',\n",
       " 'I1260.jpg',\n",
       " 'I1261.jpg',\n",
       " 'I1568.jpg',\n",
       " 'I1569.jpg',\n",
       " 'I1589.jpg',\n",
       " 'I1659.jpg',\n",
       " 'I1662.jpg',\n",
       " 'I1663.jpg',\n",
       " 'I1678.jpg',\n",
       " 'I1704.jpg',\n",
       " 'I1750.jpg',\n",
       " 'I1830.jpg',\n",
       " 'I1860.jpg',\n",
       " 'I1938.jpg',\n",
       " 'J13.jpg',\n",
       " 'J14.jpg',\n",
       " 'J15.jpg',\n",
       " 'J25.jpg',\n",
       " 'J26.jpg',\n",
       " 'J27.jpg',\n",
       " 'J37.jpg',\n",
       " 'J38.jpg',\n",
       " 'J39.jpg',\n",
       " 'K25.jpg',\n",
       " 'K26.jpg',\n",
       " 'K27.jpg',\n",
       " 'K28.jpg',\n",
       " 'L13.jpg',\n",
       " 'L14.jpg',\n",
       " 'L15.jpg',\n",
       " 'L16.jpg',\n",
       " 'L25.jpg',\n",
       " 'L26.jpg',\n",
       " 'L27.jpg',\n",
       " 'L28.jpg',\n",
       " 'M13.jpg',\n",
       " 'M14.jpg',\n",
       " 'M15.jpg',\n",
       " 'M16.jpg',\n",
       " 'M17.jpg',\n",
       " 'M25.jpg',\n",
       " 'M26.jpg',\n",
       " 'M27.jpg',\n",
       " 'M28.jpg',\n",
       " 'M29.jpg',\n",
       " 'N13.jpg',\n",
       " 'N14.jpg',\n",
       " 'N15.jpg',\n",
       " 'N16.jpg',\n",
       " 'N25.jpg',\n",
       " 'N26.jpg',\n",
       " 'N27.jpg',\n",
       " 'N28.jpg',\n",
       " 'O13.jpg',\n",
       " 'O14.jpg',\n",
       " 'O15.jpg',\n",
       " 'O16.jpg',\n",
       " 'O17.jpg',\n",
       " 'O25.jpg',\n",
       " 'O26.jpg',\n",
       " 'O27.jpg',\n",
       " 'O28.jpg',\n",
       " 'O29.jpg',\n",
       " 'P13.jpg',\n",
       " 'P14.jpg',\n",
       " 'P15.jpg',\n",
       " 'P16.jpg',\n",
       " 'P17.jpg',\n",
       " 'P25.jpg',\n",
       " 'P26.jpg',\n",
       " 'P27.jpg',\n",
       " 'P28.jpg',\n",
       " 'P29.jpg',\n",
       " 'R13.jpg',\n",
       " 'R14.jpg',\n",
       " 'R15.jpg',\n",
       " 'R16.jpg',\n",
       " 'R25.jpg',\n",
       " 'R26.jpg',\n",
       " 'R27.jpg',\n",
       " 'R28.jpg',\n",
       " 'T13.jpg',\n",
       " 'T14.jpg',\n",
       " 'T15.jpg',\n",
       " 'T16.jpg',\n",
       " 'T17.jpg',\n",
       " 'T25.jpg',\n",
       " 'T26.jpg',\n",
       " 'T27.jpg',\n",
       " 'T28.jpg',\n",
       " 'T29.jpg',\n",
       " 'T37.jpg',\n",
       " 'T38.jpg',\n",
       " 'T39.jpg',\n",
       " 'T40.jpg',\n",
       " 'T41.jpg',\n",
       " 'V13.jpg',\n",
       " 'V14.jpg',\n",
       " 'V15.jpg',\n",
       " 'V25.jpg',\n",
       " 'V26.jpg',\n",
       " 'V27.jpg',\n",
       " 'V37.jpg',\n",
       " 'V38.jpg',\n",
       " 'V39.jpg',\n",
       " 'Y13.jpg',\n",
       " 'Y14.jpg',\n",
       " 'Z13.jpg',\n",
       " 'Z14.jpg',\n",
       " 'Z15.jpg',\n",
       " 'Z16.jpg',\n",
       " 'Z25.jpg',\n",
       " 'Z26.jpg',\n",
       " 'Z27.jpg',\n",
       " 'Z28.jpg']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flowers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b081e512",
   "metadata": {},
   "source": [
    "# The model\n",
    "Using a pre-trained neural network to extract a feature vector from images and cluster the images based on how similar the feature vectors are.\n",
    "\n",
    "The pre-trained model that will be used in this tutorial is the VGG16 convolutional neural network (CNN), which is considered to be state of the art for image recognition tasks. We are going to be using this model as a feature extractor only, meaning that we will remove the final (prediction) layer so that we can obtain a feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c3aa848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels.h5\n",
      "574717952/574710816 [==============================] - 731s 1us/step\n",
      "574726144/574710816 [==============================] - 731s 1us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.models import Model\n",
    "\n",
    "model = VGG19()\n",
    "model = Model(inputs = model.inputs, outputs = model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e355608",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "This is where we put the load_img() and preprocess_input() methods to use. When loading the images we are going to set the target size to (224, 224) because the VGG model expects the images it receives to be 224x224 NumPy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9016af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file, model):\n",
    "    # load the image as a 224x224 array\n",
    "    img = load_img(file, target_size=(224,224))\n",
    "    # convert from 'PIL.Image.Image' to numpy array\n",
    "    img = np.array(img) \n",
    "    # reshape the data for the model reshape(num_of_samples, dim 1, dim 2, channels)\n",
    "    reshaped_img = img.reshape(1,224,224,3) \n",
    "    # prepare image for model\n",
    "    imgx = preprocess_input(reshaped_img)\n",
    "    # get the feature vector\n",
    "    features = model.predict(imgx, use_multiprocessing=True)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5993637",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "# lop through each image in the dataset\n",
    "for flower in flowers:\n",
    "    # try to extract the features and update the dictionary\n",
    "    try:\n",
    "        feat = extract_features(flower,model)\n",
    "        data[flower] = feat\n",
    "    # if something fails, save the extracted features as a pickle file (optional)\n",
    "    except:\n",
    "        print(\"error extracting feature from the image\")\n",
    "          \n",
    "# get a list of the filenames\n",
    "filenames = np.array(list(data.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca7a0fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of just the features\n",
    "feat = np.array(list(data.values()))\n",
    "\n",
    "# reshape so that there are 210 samples of 4096 vectors\n",
    "feat = feat.reshape(-1,4096)\n",
    "\n",
    "# get the unique labels \n",
    "unique_labels = list(map(chr, range(97, 123)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d7b80a",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction\n",
    "Simply put, if you are working with data and have a lot of variables to consider (in our case 4096), PCA allows you to reduce the number of variables while preserving as much information from the original set as possible.\n",
    "\n",
    "The number of dimensions to reduce down to is up to you and I'm sure there's a method for finding the best number of components to use, but for this case, I just chose 100 as an arbitrary number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14a08d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA for reducing the dimensions of our feature vector\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=100, random_state=22)\n",
    "pca.fit(feat)\n",
    "x = pca.transform(feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfbd19a",
   "metadata": {},
   "source": [
    "## KMeans clustering\n",
    "This algorithm will allow us to group our feature vectors into k clusters. Each cluster should contain images that are visually similar. In this case, we know there are 10 different species of flowers so we can have k = 26."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f05c29d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=26, random_state=22)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clustering and dimension reduction\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# cluster feature vectors\n",
    "kmeans = KMeans(n_clusters=len(unique_labels), random_state=22)\n",
    "kmeans.fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b254474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# holds the cluster id and the images { id: [images] }\n",
    "groups = {}\n",
    "for file, cluster in zip(filenames,kmeans.labels_):\n",
    "    if cluster not in groups.keys():\n",
    "        groups[cluster] = []\n",
    "        groups[cluster].append(file)\n",
    "    else:\n",
    "        groups[cluster].append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b4746282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that lets you view a cluster (based on identifier)        \n",
    "def view_cluster(cluster):\n",
    "    plt.figure(figsize = (25,25));\n",
    "    # gets the list of filenames for a cluster\n",
    "    files = groups[cluster]\n",
    "    # only allow up to 30 images to be shown at a time\n",
    "    if len(files) > 30:\n",
    "        print(f\"Clipping cluster size from {len(files)} to 30\")\n",
    "        files = files[:29]\n",
    "    # plot each image in the cluster\n",
    "    for index, file in enumerate(files):\n",
    "        plt.subplot(10,10,index+1);\n",
    "        img = load_img(file)\n",
    "        img = np.array(img)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5bc85b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['N13.jpg', 'N14.jpg', 'N15.jpg', 'N16.jpg', 'N25.jpg', 'N26.jpg', 'N27.jpg', 'N28.jpg']\n",
      "1 ['259.jpg', '268.jpg', '287.jpg', '289.jpg', '297.jpg', '300.jpg', '308.jpg', '309.jpg', '310.jpg', '317.jpg', '320.jpg', '327.jpg', '350.jpg', '366.jpg', '370.jpg', '377.jpg', '379.jpg', '380.jpg', '419.jpg', '437.jpg', '441.jpg', '460.jpg', '462.jpg']\n",
      "2 ['J13.jpg', 'J14.jpg', 'J15.jpg', 'J25.jpg', 'J26.jpg', 'J27.jpg', 'J37.jpg', 'J38.jpg', 'J39.jpg', 'Y13.jpg', 'Y14.jpg']\n",
      "3 ['1257.jpg', '1261.jpg', '1290.jpg', '1297.jpg', '1318.jpg', '1330.jpg', '1337.jpg', '1338.jpg', '1341.jpg', '1377.jpg', '1378.jpg', '1379.jpg', '1397.jpg', '1399.jpg', '1400.jpg', '1409.jpg', '1418.jpg', '1448.jpg', '1449.jpg']\n",
      "4 ['T13.jpg', 'T14.jpg', 'T15.jpg', 'T16.jpg', 'T17.jpg', 'T25.jpg', 'T26.jpg', 'T27.jpg', 'T28.jpg', 'T29.jpg', 'T37.jpg', 'T38.jpg', 'T39.jpg', 'T40.jpg', 'T41.jpg']\n",
      "5 ['del1310.jpg', 'del1313.jpg', 'del1528.jpg', 'del1603.jpg']\n",
      "6 ['C1.jpg', 'C13.jpg', 'C14.jpg', 'C15.jpg', 'C2.jpg', 'C25.jpg', 'C26.jpg', 'C27.jpg', 'C3.jpg', 'C37.jpg', 'C38.jpg', 'C39.jpg', 'C49.jpg', 'C50.jpg', 'C51.jpg']\n",
      "7 ['E349.jpg', 'E350.jpg', 'E351.jpg']\n",
      "8 ['K25.jpg', 'K26.jpg', 'K27.jpg', 'K28.jpg', 'V13.jpg', 'V14.jpg', 'V15.jpg', 'V25.jpg', 'V26.jpg', 'V27.jpg', 'V37.jpg', 'V38.jpg', 'V39.jpg']\n",
      "9 ['E361.jpg', 'E362.jpg', 'E363.jpg', 'E373.jpg', 'E374.jpg', 'E375.jpg', 'E385.jpg', 'E386.jpg', 'E387.jpg']\n",
      "10 ['G1.jpg', 'G13.jpg', 'G14.jpg', 'G15.jpg', 'G2.jpg', 'G25.jpg', 'G26.jpg', 'G27.jpg', 'G3.jpg', 'G37.jpg', 'G38.jpg', 'G39.jpg', 'G49.jpg', 'G50.jpg', 'G51.jpg']\n",
      "11 ['I1260.jpg', 'I1261.jpg', 'I1568.jpg', 'I1569.jpg', 'I1589.jpg', 'I1659.jpg', 'I1662.jpg', 'I1663.jpg', 'I1678.jpg', 'I1704.jpg', 'I1750.jpg', 'I1830.jpg', 'I1860.jpg', 'I1938.jpg']\n",
      "12 ['A133.jpg', 'A134.jpg', 'A135.jpg', 'A61.jpg', 'A62.jpg', 'A63.jpg']\n",
      "13 ['P13.jpg', 'P14.jpg', 'P15.jpg', 'P16.jpg', 'P17.jpg', 'P25.jpg', 'P26.jpg', 'P27.jpg', 'P28.jpg', 'P29.jpg']\n",
      "14 ['1217.jpg', '1220.jpg', '1221.jpg', '1237.jpg', '1238.jpg', '1239.jpg', '1247.jpg', '1248.jpg', '1250.jpg', '1251.jpg', '1277.jpg', '1279.jpg', '1349.jpg', '1350.jpg', '1440.jpg', '1441.jpg']\n",
      "15 ['D25.jpg', 'D26.jpg', 'D27.jpg', 'D37.jpg', 'D38.jpg', 'D39.jpg']\n",
      "16 ['301.jpg', '391.jpg', '394.jpg', '403.jpg', '404.jpg', '422.jpg', '433.jpg', '467.jpg', '473.jpg']\n",
      "17 ['Z13.jpg', 'Z14.jpg', 'Z15.jpg', 'Z16.jpg', 'Z25.jpg', 'Z26.jpg', 'Z27.jpg', 'Z28.jpg']\n",
      "18 ['R13.jpg', 'R14.jpg', 'R15.jpg', 'R16.jpg', 'R25.jpg', 'R26.jpg', 'R27.jpg', 'R28.jpg']\n",
      "19 ['H37.jpg', 'H38.jpg', 'H39.jpg', 'H49.jpg', 'H50.jpg', 'H51.jpg']\n",
      "20 ['L13.jpg', 'L14.jpg', 'L15.jpg', 'L16.jpg', 'L25.jpg', 'L26.jpg', 'L27.jpg', 'L28.jpg']\n",
      "21 ['1.jpg', '214.jpg', '222.jpg', '24.jpg', '44.jpg']\n",
      "22 ['M13.jpg', 'M14.jpg', 'M15.jpg', 'M16.jpg', 'M17.jpg', 'M25.jpg', 'M26.jpg', 'M27.jpg', 'M28.jpg', 'M29.jpg']\n",
      "23 ['del1002.jpg', 'del1028.jpg', 'del1031.jpg', 'del1040.jpg', 'del1129.jpg', 'del1133.jpg', 'del1138.jpg', 'del1160.jpg', 'del1169.jpg', 'del1180.jpg', 'del1782.jpg']\n",
      "24 ['O13.jpg', 'O14.jpg', 'O15.jpg', 'O16.jpg', 'O17.jpg', 'O25.jpg', 'O26.jpg', 'O27.jpg', 'O28.jpg', 'O29.jpg']\n",
      "25 ['A1.jpg', 'A13.jpg', 'A14.jpg', 'A15.jpg', 'A2.jpg', 'A25.jpg', 'A26.jpg', 'A27.jpg', 'A3.jpg']\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "parent_dir = r\"C:\\Users\\matan\\My PC (DESKTOP-RLTMVS3)\\Desktop\\פרויקט גמר\\dataset\\dark photos\"\n",
    "\n",
    "for i in range(len(groups)):\n",
    "    path = os.path.join(parent_dir, str(i))\n",
    "    os.makedirs(path)\n",
    "    for s in groups[i]:\n",
    "        if os.path.isfile(s): \n",
    "            shutil.move(s, path)\n",
    "    print(i, groups[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
